app.name = Data Traffic Monitoring
app.description=${app.name} is a Spring Boot application

# dtm
dtm.name = Data Traffic Monitoring

# tshark
dtm.tool.tshark.path = C:\\tools\\Wireshark
dtm.tool.tshark.exe = tshark.exe
dtm.tool.tshark.fields = -T fields -e frame.number -e frame.time_delta -e frame.time -e frame.interface_name -e frame.interface_id -e frame.interface_description -e frame.cap_len -e frame.len -e frame.protocols -e eth.src -e eth.dst -e ip.src -e ip.dst -e ip -e ip.proto -e ip.src_host -e ip.dst_host -e tcp.port -e udp.port -e ipv6 -e ipv6.addr -e ipv6.src -e ipv6.dst -e http.host -e dns.qry.name -e tcp.stream -e tcp.srcport -e tcp.dstport -e udp.srcport -e udp.dstport -e _ws.col.Info -E separator=/t -E quote=n -E occurrence=f
dtm.tool.tshark.logDir = C:\\tools\\tshark
dtm.tool.tshark.logFiles = 2
dtm.tool.tshark.logDuration = 60
dtm.tool.tshark.persistDir =  C:\\tools\\tshark-persist
dtm.tool.tshark.pcap = c:\\tools\\test\\fpcap.pcap
# values: all| eth0 | ciscodump | ...
# dtm.tool.tshark.source = \\Device\\NPF_{05F38A86-2E62-4ACF-A1FF-80D5CE84914D}
dtm.tool.tshark.source = all

# sftp
dtm.tool.tshark.sftpHost =${SFTP_HOST:10.233.100.183}
dtm.tool.tshark.sftpPort = ${SFTP_PORT:22}
dtm.tool.tshark.sftpPassword = ${SFTP_PASSWORD:sftp_sphinx}
dtm.tool.tshark.sftpUsername =  ${SFTP_USERNAME:sftp_sphinx}
#dtm.tool.tshark.sftpPrivateKeyPath = C:\\tools\\sftp_sphinx_rsa
dtm.tool.tshark.sftpUploadDirectory = /home/sftp_sphinx/upload

# suricata
dtm.tool.suricata.path = C:\\tools\\Suricata
dtm.tool.suricata.exe = suricata.exe
dtm.tool.suricata.log =  C:\\tools\\Suricata\\log
dtm.tool.suricata.yaml = C:\\tools\\Suricata\\suricata.yaml
# values: java|tshark
dtm.tool.suricata.networkInterfaceDiscoveyAlgorithm = java
# values: all| eth0 | ciscodump | ...
# dtm.tool.suricata.source = 192.168.1.8
dtm.tool.suricata.source = all

# logstash
dtm.tool.logstash.path = C:\\tools\\logstash
dtm.tool.logstash.exe = logstash.bat
dtm.tool.logstash.suricataConf = logstash.conf
dtm.tool.logstash.nfstreamConf = logstashNf-folder.conf

# nfstream
dtm.tool.nfstream.path = /nfstream
dtm.tool.nfstream.exe = python3
# all interfaces: ###
#dtm.tool.nfstream.source = ###
dtm.tool.nfstream.source = ${SOURCE:ens160}
dtm.tool.nfstream.csv = /nfstream/flowNf.csv
#dtm.tool.nfstream.pythonFile = C:\\work\\SPHINX\\data-traffic-monitoring\\src\\test\\resources\\feature-test.py
dtm.tool.nfstream.pythonFile = /nfstream/nfstream/features-collect.py
#dtm.tool.nfstream.collectFunction = collectTest
dtm.tool.nfstream.collectFunction = collect

dtm.restTemplate.disableSSLValidation = true

server.servlet.context-path=/sphinx/dtm
server.port = 8087

# spring-jpa
spring.jpa.properties.hibernate.dialect = org.hibernate.dialect.PostgreSQLDialect
spring.jpa.hibernate.ddl-auto=none
spring.jpa.hibernate.show-sql=true

spring.datasource.driver-class-name=org.postgresql.Driver
spring.datasource.url=jdbc:postgresql://localhost:8432/sphinx
spring.datasource.username=sphinx
spring.datasource.password=sphinx
spring.liquibase.change-log=classpath:/sphinx/update.xml
logging.level.liquibase = INFO

# logging

# logging.file.path & logging.file.name:you should only set one
#logging.file.path=c:\\logs
logging.file.name=c:\\logs\\dtm.log
logging.pattern.rolling-file-name=c:\\logs\\dtm-%d{yyyy-MM-dd}.%i.log
#logging.pattern.rolling-file-name=c:\\logs\\dtm-%d{yyyy-MM-dd-HH-mm-ss}.%i.log
# log file size
logging.file.max-size=20MB
# the total size of all log files under a specified number
logging.file.total-size-cap=600MB
# maximum number of days that the archive log files are kept
logging.file.max-history=30
logging.file.clean-history-on-start=true

# management
management.endpoint.health.enabled=true
management.endpoint.health.show-details=always
management.endpoint.metrics.enabled=true
management.endpoint.info.enabled=true
management.endpoints.web.exposure.include=info,health,metrics
#management.endpoints.web.exposure.include=*
management.endpoints.web.exposure.exclude=
management.endpoints.jmx.exposure.include=*
management.endpoints.jmx.exposure.exclude=

# kafka
dtm.exchange.name = tshark-sphinx-Exchange
dtm.routing.key.name = tshark-sphinx-RoutingKey

ad.alert.queue.name = AnomalyDetectionAlert-Queue
ad.alert.exchange.name = AnomalyDetectionAlert-Exchange
ad.alert.routing.key.name = AnomalyDetectionAlert-RoutingKey

spring.kafka.bootstrap-servers=localhost:9092
#spring.kafka.clientId=dtm
kafka.group.id=dtm

topic.metric = dtm-metric
topic.alert = dtm-alert
topic.event = dtm-event
topic.package = dtm-package
topic.asset = ${TOPIC_ASSET:dtm-asset}
topic.dss-dtm-record = ${TOPIC_DSS:dss-dtm-record-traffic}
topic.package.enable = false

tshark.statistics.scheduler = */10 * * * * *

# sm
# SM_IP
sphinx.sm.ip=${SM_IP:http://sphinx-toolkit.intracom-telecom.com/SMPlatform/manager/rst}
sphinx.sm.kafkaAuthentication=/KafkaAuthentication
sphinx.sm.username=${KAFKA_USERNAME:kafkauser}

sphinx.sm.password=${KAFKA_PASSWORD:kafkauser123}

# OSS: trebuie neapartat SIEM
oauth.client.id=${OAUTH_CLIENT_ID:SIEM}
oauth.token.endpoint.uri=${OAUTH_TOKEN_ENDPOINT_URI:http://sphinx-toolkit.intracom-telecom.com/SMPlatform/manager/rst/getKafkaToken}