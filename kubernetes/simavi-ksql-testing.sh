ksqldbserverpod=$(kubectl get pods -o=name --selector=channels=ksql)
sleep 4s
kubectl exec --stdin --tty $ksqldbserverpod -- ksql http://ksqldb-server:8088
sleep 10s

SET 'auto.offset.reset'='earliest';

sleep 5s

CREATE STREAM AD_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_ad', VALUE_FORMAT='JSON', PARTITIONS=1);
sleep 5s

CREATE STREAM DTM_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_dtm', VALUE_FORMAT='JSON', PARTITIONS=1);
sleep 5s


CREATE STREAM AE_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_ae', VALUE_FORMAT='JSON', PARTITIONS=1);
sleep 5s


CREATE STREAM BBTR_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_bbtr', VALUE_FORMAT='JSON', PARTITIONS=1);
sleep 5s


CREATE STREAM HP_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_hp', VALUE_FORMAT='JSON', PARTITIONS=1);
sleep 5s

CREATE STREAM RCRA_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_rcra', VALUE_FORMAT='JSON', PARTITIONS=1);
sleep 5s

CREATE STREAM KB_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_kb', VALUE_FORMAT='JSON', PARTITIONS=1);
sleep 5s

CREATE STREAM DSS_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_dss', VALUE_FORMAT='JSON', PARTITIONS=1);
sleep 5s

CREATE STREAM VAAAS_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_vaaas', VALUE_FORMAT='JSON', PARTITIONS=1);
sleep 5s


CREATE STREAM SIEM_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_siem', VALUE_FORMAT='JSON', PARTITIONS=1);
sleep 5s



CREATE STREAM JDBC_SOURCE_AVRO 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, TOOL VARCHAR, STATUS VARCHAR, ACTION VARCHAR, DETAILS VARCHAR, SENT VARCHAR) \
        WITH (KAFKA_TOPIC='JDBC_SOURCE_AVRO', PARTITIONS=1, VALUE_FORMAT='AVRO');
sleep 5s

INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'AD' AS TOOL, '--' AS STATUS, ACTION, DETAILS, 'false' AS SENT FROM AD_JDBC_SOURCE_JSON;
sleep 5s
INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'DTM' AS TOOL, '--' AS STATUS,  ACTION, DETAILS, 'false' AS SENT FROM DTM_JDBC_SOURCE_JSON;
sleep 5s
INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'AE' AS TOOL, '--' AS STATUS,  ACTION, DETAILS, 'false' AS SENT FROM AE_JDBC_SOURCE_JSON;
sleep 5s
INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'BBTR' AS TOOL, '--' AS STATUS,  ACTION, DETAILS, 'false' AS SENT FROM BBTR_JDBC_SOURCE_JSON;
sleep 5s
INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'HP' AS TOOL, '--' AS STATUS,  ACTION, DETAILS, 'false' AS SENT FROM HP_JDBC_SOURCE_JSON;
sleep 5s
INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'RCRA' AS TOOL, '--' AS STATUS,  ACTION, DETAILS, 'false' AS SENT FROM RCRA_JDBC_SOURCE_JSON;
sleep 5s
INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'KB' AS TOOL, '--' AS STATUS,  ACTION, DETAILS, 'false' AS SENT FROM KB_JDBC_SOURCE_JSON;
sleep 5s
INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'DSS' AS TOOL, '--' AS STATUS,  ACTION, DETAILS, 'false' AS SENT FROM DSS_JDBC_SOURCE_JSON;
sleep 5s
INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'VAAAS' AS TOOL, '--' AS STATUS,  ACTION, DETAILS, 'false' AS SENT FROM VAAAS_JDBC_SOURCE_JSON;
sleep 5s
INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'SIEM' AS TOOL, '--' AS STATUS,  ACTION, DETAILS, 'false' AS SENT FROM SIEM_JDBC_SOURCE_JSON;
sleep 5s


CREATE SINK CONNECTOR jdbc_dest_4 WITH (
  'connector.class'          = 'io.confluent.connect.jdbc.JdbcSinkConnector',
  'connection.url'           = 'jdbc:postgresql://sphinx-postgres:5432/sphinx',
  'connection.user'          = 'sphinx',
  'connection.password'      = 'sphinx',
  'tasks.max'		     = '10',
  'mode'                     = 'incrementing',
  'key'                      = 'id',
  'key.converter'            = 'org.apache.kafka.connect.converters.IntegerConverter',
  'value.converter'          = 'io.confluent.connect.avro.AvroConverter',
  'value.converter.schema.registry.url'= 'http://schema-registry-service:8081',
  'key.converter.schemas.enable' = false,
  'value.converter.schemas.enable' = true,
  'pk.mode'                  = 'none',
  'topics'                    = 'JDBC_SOURCE_AVRO',
  'table.name.format'        = 'kafka_${topic}',
  'auto.create'              = true
);

sleep 20s

postgresdbpod=$(kubectl get pods -o=name --selector=tier=simavidb)
kubectl exec --stdin $postgresdbpod -- psql -h localhost -U sphinx -p 5432 sphinx -c "SELECT * FROM \"kafka_JDBC_SOURCE_AVRO\""