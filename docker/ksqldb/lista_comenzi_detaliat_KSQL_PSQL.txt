10 componente:
AD	Anomaly Detection
DTM	Data Traffic Monitoring
AE	Analytic Engine
BBTR	Blockchain Based Threats Registry
HP	Artificial Intelligence Honeypot
RCRA	Real-time Cyber Risk Assesment
KB	Knowledge Base
DSS	Decision Support System
VAaaS	Vulnerability Assesment as a Service
SIEM	Security Information and Event Management


LOCATION - OPTIONAL, ma gandesc sa nu-l folosim


| ALERT NUMBER(SORT) |  DESCRIPTION | TIMESTAMP | LOCATION | INDICATION(SORT) | SPHINX TOOL(SORT) | STATUS(SORT) | PROPOSED ACTION | DETAILS |
 			              		                CRITICAL		               CLOSED
 			                                         ALERT		                       IGNORE
 			                                         ERROR                               ACKNOWLEDGE
 			                                     INFORMATIONAL                              OPEN
									     		      --

ID INT PRIMARY KEY 
DESCRIPTION VARCHAR NOT NULL,
TIMESTAMP TIMESTAMP NOT NULL,
LOCATION VARCHAR,
INDICATION VARCHAR VARCHAR NOT NULL,
SPHINX TOOL VARCHAR NOT NULL,
STATUS VARCHAR,
ACTION VARCHAR,
DETAILS VARCHAR


Components  => DESCRIPTION, TIMESTAMP, LOCATION, INDICATION, ACTION, DETAILS  ====(IN KSQL)====> DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, LOCATION VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR
(10 tables)


UNION 	    => ID, ALERT, DESCRIPTION, TIMESTAMP, LOCATION, INDICATION, SPHINX TOOL, STATUS, ACTION, DETAILS 
====(IN KSQL)====> ID INT PRIMARY KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, LOCATION VARCHAR, INDICATION VARCHAR, SPHINX TOOL VARCHAR, STATUS VARCHAR, ACTION VARCHAR, DETAILS VARCHAR





-----------------------------------------------------------------------------------------------------------
COMENZI: 
------PSQL-----

CREATE TABLE public.table_source_ad (
	DESCRIPTION VARCHAR NOT NULL,
	TIMESTAMP TIMESTAMP NOT NULL,
	INDICATION VARCHAR NOT NULL,
	ACTION VARCHAR,
	DETAILS VARCHAR
);


CREATE TABLE public.table_source_dtm (
	DESCRIPTION VARCHAR NOT NULL,
	TIMESTAMP TIMESTAMP NOT NULL,
	INDICATION VARCHAR NOT NULL,
	ACTION VARCHAR,
	DETAILS VARCHAR
);


CREATE TABLE public.table_source_ae (
	DESCRIPTION VARCHAR NOT NULL,
	TIMESTAMP TIMESTAMP NOT NULL,
	INDICATION VARCHAR NOT NULL,
	ACTION VARCHAR,
	DETAILS VARCHAR
);


CREATE TABLE public.table_source_bbtr (
	DESCRIPTION VARCHAR NOT NULL,
	TIMESTAMP TIMESTAMP NOT NULL,
	INDICATION VARCHAR NOT NULL,
	ACTION VARCHAR,
	DETAILS VARCHAR
);


CREATE TABLE public.table_source_hp (
	DESCRIPTION VARCHAR NOT NULL,
	TIMESTAMP TIMESTAMP NOT NULL,
	INDICATION VARCHAR NOT NULL,
	ACTION VARCHAR,
	DETAILS VARCHAR
);


CREATE TABLE public.table_source_rcra (
	DESCRIPTION VARCHAR NOT NULL,
	TIMESTAMP TIMESTAMP NOT NULL,
	INDICATION VARCHAR NOT NULL,
	ACTION VARCHAR,
	DETAILS VARCHAR
);

CREATE TABLE public.table_source_kb (
	DESCRIPTION VARCHAR NOT NULL,
	TIMESTAMP TIMESTAMP NOT NULL,
	INDICATION VARCHAR NOT NULL,
	ACTION VARCHAR,
	DETAILS VARCHAR
);


CREATE TABLE public.table_source_dss (
	DESCRIPTION VARCHAR NOT NULL,
	TIMESTAMP TIMESTAMP NOT NULL,
	INDICATION VARCHAR NOT NULL,
	ACTION VARCHAR,
	DETAILS VARCHAR
);


CREATE TABLE public.table_source_vaaas (
	DESCRIPTION VARCHAR NOT NULL,
	TIMESTAMP TIMESTAMP NOT NULL,
	INDICATION VARCHAR NOT NULL,
	ACTION VARCHAR,
	DETAILS VARCHAR
);


CREATE TABLE public.table_source_siem (
	DESCRIPTION VARCHAR NOT NULL,
	TIMESTAMP TIMESTAMP NOT NULL,
	INDICATION VARCHAR NOT NULL,
	ACTION VARCHAR,
	DETAILS VARCHAR
);


----- KSQL -----

CREATE SOURCE CONNECTOR jdbc_source_2 WITH (
  'connector.class'          = 'io.confluent.connect.jdbc.JdbcSourceConnector',
  'connection.url'           = 'jdbc:postgresql://sphinx-postgres:5432/sphinx',
  'connection.user'          = 'sphinx',
  'connection.password'      = 'sphinx',
  'topic.prefix'             = 'jdbc_',
  'table.whitelist'          = 'table_source_ad, table_source_ae, table_source_bbtr, table_source_dss, table_source_dtm, table_source_hp, table_source_kb, table_source_rcra, table_source_siem, table_source_vaaas',
  'mode'                     = 'bulk'
);
# mode = |bulk, timestamp, incrementing, timestamp+incrementing|
SET 'auto.offset.reset'='earliest';


CREATE STREAM AD_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_ad', VALUE_FORMAT='JSON', PARTITIONS=1);

CREATE STREAM DTM_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_dtm', VALUE_FORMAT='JSON', PARTITIONS=1);


CREATE STREAM AE_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_ae', VALUE_FORMAT='JSON', PARTITIONS=1);


CREATE STREAM BBTR_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_bbtr', VALUE_FORMAT='JSON', PARTITIONS=1);


CREATE STREAM HP_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_hp', VALUE_FORMAT='JSON', PARTITIONS=1);

CREATE STREAM RCRA_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_rcra', VALUE_FORMAT='JSON', PARTITIONS=1);

CREATE STREAM KB_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_kb', VALUE_FORMAT='JSON', PARTITIONS=1);

CREATE STREAM DSS_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_dss', VALUE_FORMAT='JSON', PARTITIONS=1);

CREATE STREAM VAAAS_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_vaaas', VALUE_FORMAT='JSON', PARTITIONS=1);


CREATE STREAM SIEM_JDBC_SOURCE_JSON 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='jdbc_table_source_siem', VALUE_FORMAT='JSON', PARTITIONS=1);



CREATE STREAM JDBC_SOURCE_AVRO 
	(ID INT KEY, DESCRIPTION VARCHAR, TIMESTAMP VARCHAR, INDICATION VARCHAR, TOOL VARCHAR, STATUS VARCHAR, ACTION VARCHAR, DETAILS VARCHAR) \
        WITH (KAFKA_TOPIC='JDBC_SOURCE_AVRO', PARTITIONS=1, VALUE_FORMAT='AVRO');

INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'AD' AS TOOL, '--' AS STATUS, ACTION, DETAILS FROM AD_JDBC_SOURCE_JSON;
INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'DTM' AS TOOL, '--' AS STATUS,  ACTION, DETAILS FROM DTM_JDBC_SOURCE_JSON;
INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'AE' AS TOOL, '--' AS STATUS,  ACTION, DETAILS FROM AE_JDBC_SOURCE_JSON;
INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'BBTR' AS TOOL, '--' AS STATUS,  ACTION, DETAILS FROM BBTR_JDBC_SOURCE_JSON;
INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'HP' AS TOOL, '--' AS STATUS,  ACTION, DETAILS FROM HP_JDBC_SOURCE_JSON;
INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'RCRA' AS TOOL, '--' AS STATUS,  ACTION, DETAILS FROM RCRA_JDBC_SOURCE_JSON;
INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'KB' AS TOOL, '--' AS STATUS,  ACTION, DETAILS FROM KB_JDBC_SOURCE_JSON;
INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'DSS' AS TOOL, '--' AS STATUS,  ACTION, DETAILS FROM DSS_JDBC_SOURCE_JSON;
INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'VAAAS' AS TOOL, '--' AS STATUS,  ACTION, DETAILS FROM VAAAS_JDBC_SOURCE_JSON;
INSERT INTO JDBC_SOURCE_AVRO SELECT ID, DESCRIPTION, TIMESTAMP, INDICATION, 'SIEM' AS TOOL, '--' AS STATUS,  ACTION, DETAILS FROM SIEM_JDBC_SOURCE_JSON;


CREATE SINK CONNECTOR jdbc_dest_4 WITH (
  'connector.class'          = 'io.confluent.connect.jdbc.JdbcSinkConnector',
  'connection.url'           = 'jdbc:postgresql://sphinx-postgres:5432/sphinx',
  'connection.user'          = 'sphinx',
  'connection.password'      = 'sphinx',
  'tasks.max'		     = '10',
  'mode'                     = 'incrementing',
  'key'                      = 'id',
  'key.converter'            = 'org.apache.kafka.connect.converters.IntegerConverter',
  'value.converter'          = 'io.confluent.connect.avro.AvroConverter',
  'value.converter.schema.registry.url'= 'http://cp-schema-registry:8081',
  'key.converter.schemas.enable' = false,
  'value.converter.schemas.enable' = true,
  'pk.mode'                  = 'none',
  'topics'                    = 'JDBC_SOURCE_AVRO',
  'table.name.format'        = 'kafka_${topic}',
  'auto.create'              = true
);


INSERT INTO table_source_ad (DESCRIPTION, TIMESTAMP, INDICATION, ACTION, DETAILS) VALUES ('Vulnerability detected', '2020-08-18 16:20:00', 'CRITICAL', '-', 'Check the switch ports');
INSERT INTO table_source_ae (DESCRIPTION, TIMESTAMP, INDICATION, ACTION, DETAILS) VALUES ('Vulnerability detected', '2020-08-18 16:20:00', 'CRITICAL', '-', 'Check the switch ports');
INSERT INTO table_source_bbtr (DESCRIPTION, TIMESTAMP, INDICATION, ACTION, DETAILS) VALUES ('Vulnerability detected', '2020-08-18 16:20:00', 'CRITICAL', '-', 'Check the switch ports');
INSERT INTO table_source_dss (DESCRIPTION, TIMESTAMP, INDICATION, ACTION, DETAILS) VALUES ('Vulnerability detected', '2020-08-18 16:20:00', 'CRITICAL', '-', 'Check the switch ports');
INSERT INTO table_source_dtm (DESCRIPTION, TIMESTAMP, INDICATION, ACTION, DETAILS) VALUES ('Vulnerability detected', '2020-08-18 16:20:00', 'CRITICAL', '-', 'Check the switch ports');
INSERT INTO table_source_hp (DESCRIPTION, TIMESTAMP, INDICATION, ACTION, DETAILS) VALUES ('Vulnerability detected', '2020-08-18 16:20:00', 'CRITICAL', '-', 'Check the switch ports');
INSERT INTO table_source_kb (DESCRIPTION, TIMESTAMP, INDICATION, ACTION, DETAILS) VALUES ('Vulnerability detected', '2020-08-18 16:20:00', 'CRITICAL', '-', 'Check the switch ports');
INSERT INTO table_source_rcra (DESCRIPTION, TIMESTAMP, INDICATION, ACTION, DETAILS) VALUES ('Vulnerability detected', '2020-08-18 16:20:00', 'CRITICAL', '-', 'Check the switch ports');
INSERT INTO table_source_siem (DESCRIPTION, TIMESTAMP, INDICATION, ACTION, DETAILS) VALUES ('Vulnerability detected', '2020-08-18 16:20:00', 'CRITICAL', '-', 'Check the switch ports');
INSERT INTO table_source_vaaas (DESCRIPTION, TIMESTAMP, INDICATION, ACTION, DETAILS) VALUES ('Vulnerability detected', '2020-08-18 16:20:00', 'CRITICAL', '-', 'Check the switch ports');

DELETE FROM table_source_ad WHERE INDICATION = 'CRITICAL';
DELETE FROM table_source_ae WHERE INDICATION = 'CRITICAL';
DELETE FROM table_source_bbtr WHERE INDICATION = 'CRITICAL';
DELETE FROM table_source_dss WHERE INDICATION = 'CRITICAL';
DELETE FROM table_source_dtm WHERE INDICATION = 'CRITICAL';
DELETE FROM table_source_hp WHERE INDICATION = 'CRITICAL';
DELETE FROM table_source_kb WHERE INDICATION = 'CRITICAL';
DELETE FROM table_source_rcra WHERE INDICATION = 'CRITICAL';
DELETE FROM table_source_siem WHERE INDICATION = 'CRITICAL';
DELETE FROM table_source_vaaas WHERE INDICATION = 'CRITICAL';

ALTER TABLE sphinx."kafka_JDBC_SOURCE_AVRO"
ADD COLUMN id SERIAL PRIMARY KEY;