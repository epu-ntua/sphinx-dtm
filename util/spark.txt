1. download:
    https://www.apache.org/dyn/closer.lua/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz
2. unzip to c:\tools\spark
3. (env)SPARK_HOME: c:\tools\spark

4. download:
    https://github.com/cdarlint/winutils/tree/master/hadoop-3.2.1/bin
    => C:\tools\winutils\bin\winutils.exe
5. (env)HADOOP_HOME: C:\tools\winutils

6. pornire spark
    cd c:\tools\spark\bin
    spark-class org.apache.spark.deploy.master.Master
    verificare: http://localhost:8080/

Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
20/12/03 16:39:52 INFO Master: Started daemon with process name: 3860@MMM
20/12/03 16:39:53 INFO SecurityManager: Changing view acls to: XXX
20/12/03 16:39:53 INFO SecurityManager: Changing modify acls to: XXX
20/12/03 16:39:53 INFO SecurityManager: Changing view acls groups to:
20/12/03 16:39:53 INFO SecurityManager: Changing modify acls groups to:
20/12/03 16:39:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(XXX); groups with view permissions: Set(); users  with modify permissions: Set(IulianB); groups with modify permissions: Set()
20/12/03 16:39:59 INFO Utils: Successfully started service 'sparkMaster' on port 7077.
20/12/03 16:39:59 INFO Master: Starting Spark master at spark://172.18.252.148:7077
20/12/03 16:39:59 INFO Master: Running Spark version 3.0.1
20/12/03 16:39:59 INFO Utils: Successfully started service 'MasterUI' on port 8080.
20/12/03 16:39:59 INFO MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://hbaseserver:8080
20/12/03 16:40:00 INFO Master: I have been elected leader! New state: ALIVE

7. pornire worker
    cd c:\tools\spark\bin
    spark-class org.apache.spark.deploy.worker.Worker spark://172.18.252.171:7077

Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
20/12/03 16:43:20 INFO Worker: Started daemon with process name: 9408@MMMM
20/12/03 16:43:21 INFO SecurityManager: Changing view acls to: XXX
20/12/03 16:43:21 INFO SecurityManager: Changing modify acls to: XXXX
20/12/03 16:43:21 INFO SecurityManager: Changing view acls groups to:
20/12/03 16:43:21 INFO SecurityManager: Changing modify acls groups to:
20/12/03 16:43:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(XXXX); groups with view permissions: Set(); users  with modify permissions: Set(IulianB); groups with modify permissions: Set()
20/12/03 16:43:27 INFO Utils: Successfully started service 'sparkWorker' on port 56658.
20/12/03 16:43:27 INFO Worker: Starting Spark worker 172.18.252.148:56658 with 8 cores, 13.0 GiB RAM
20/12/03 16:43:27 INFO Worker: Running Spark version 3.0.1
20/12/03 16:43:27 INFO Worker: Spark home: C:\tools\spark
20/12/03 16:43:27 INFO ResourceUtils: ==============================================================
20/12/03 16:43:27 INFO ResourceUtils: Resources for spark.worker:

20/12/03 16:43:27 INFO ResourceUtils: ==============================================================
20/12/03 16:43:27 WARN Utils: Service 'WorkerUI' could not bind on port 8081. Attempting port 8082.
20/12/03 16:43:27 INFO Utils: Successfully started service 'WorkerUI' on port 8082.
20/12/03 16:43:27 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://hbaseserver:8082
20/12/03 16:43:27 INFO Worker: Connecting to master 172.18.252.148:7077...
20/12/03 16:43:27 INFO TransportClientFactory: Successfully created connection to /172.18.252.148:7077 after 54 ms (0 ms spent in bootstraps)
20/12/03 16:43:28 INFO Worker: Successfully registered with master spark://172.18.252.148:7077

8. pornire spark-shell
    cd c:\tools\spark\bin
    spark-shell --master spark://172.18.252.148:7077

Obs:
    1. daca nu e pornit server-ul (server master) de spark o sa crape
    2. daca nu e pornit si un worker (server worker) de spark, o sa tot incerce, pana cand probabil o sa crape...
        Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

Alte probleme:
    1. java.lang.ClassCastException:
        cannot assign instance of java.lang.invoke.SerializedLambda to field org.apache.spark.rdd.MapPartitionsRDD.f of type scala.Function3
        in instance of org.apache.spark.rdd.MapPartitionsRDD

    https://community.cloudera.com/t5/Support-Questions/Caused-by-java-lang-ClassCastException-cannot-assign/td-p/209202
